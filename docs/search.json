[
  {
    "objectID": "QRintro.html",
    "href": "QRintro.html",
    "title": "QR Page",
    "section": "",
    "text": "Live Demo\nClick this link to view my live demo!\n\n\n\n\n\n\n\n\nBlog\nClick this link to learn more about my project!"
  },
  {
    "objectID": "posts/PossibleStrats/possible_strats.html",
    "href": "posts/PossibleStrats/possible_strats.html",
    "title": "Basic Strategies",
    "section": "",
    "text": "Basic Strategies\nThis po"
  },
  {
    "objectID": "posts/AWS_lambda_schedule/AWS_Lambda.html",
    "href": "posts/AWS_lambda_schedule/AWS_Lambda.html",
    "title": "Lambda Functions for Stopping and Starting EC2 Instance",
    "section": "",
    "text": "Intro\nEC2 instances can be expensive to run, expecially if left unchecked. As I am building a trading bot that is only going to be running during market hours.\nTo do this we will be using two different tools within the AWS space: - Amazon EventBridger: Allows us to schedule lambda functions - Lambda: allows us to create event driven functions\n\n\nLambda\nThe purpose of lambda is to create event driven functions that can aid in numerous tasks.\nIn order to create a lambda function we need to first navigate to the Lambda page within our AWS console.\nWhen we get to our page we need to click “Functions” Under the “Lambda” subheader on the left hand navigation bar.\nThen we can click the create function button.\nThere are a few things that we need to do: - check that the “Author from scratch” box is checked - fill out the “Basic Information” section, ensuring that you name your function and adjust the language from the default of “Node.js 22.x” to the latest version of Python.\nFrom there we can click “Create function.”\nAfter you create your lambda function you will then need to navigate to the lambda functions page, as your were before.\nClick the instance that you just created From there you will navigate to “Code” under the Function Overview section\nBeneath the Code section your will see an editor with some basic code for an example.\nFrom there you will delete that code and replace it with the following:\nimport boto3\nchange the region name below \nregion = 'us-east-2'\n#change the Instance ID \ninstances = ['i-**************']\nec2 = boto3.client('ec2', region_name=region)\n\ndef lambda_handler(event, context):\n    # Start instances\n    ec2.start_instances(InstanceIds=instances)\n    print(f\"Started your instances: {instances}\")\nSome notes on the code:\n\nboto3 package is used for connect and control different AWS services. The code above is using it for ‘ec2’ as we can tell\nour function takes two inputs:\n\nevent\ncontext\n\n\nWithin the function we start the ec2 instance with “ec2.start_instances()” the instance variable is your ec2 instance id which will be in a similar format to ‘i-**************’ and the region, will be the region which those instances are in, you can find both of these variables in your EC2 dashboard.\nOnce you update your code ensure that you Deploy the code updating the function.\nOnce you have updated and deployed your code we can test the function by going to the test section, and clicking “Test.”\nYou should get an error, this is because we don’t have the right permissions.\nYou need to navigate to the search bar and type “IAM.” IAM stands for Identity and Access Management, this page is used to control different users and role access for security purposes.\nIn this you need to click “Roles” in the left nav bar. Within this section you will look for the name of your lambda function, click on your function. Search for AmazonEC2FullAccess we are using this for simplicity as if allows your lambda function full access to your EC2 instance, add it to the roles permissions.\nNow if we go back to our lambda function and test it, the test should produce positive results, we can ensure that our function is running by navigating to our EC2 dashboard.\nWe want to create another lambda function to stop the EC2 as well, for this we will go through thesame steps, but using this code for the function instead:\nimport boto3\nchange the region name below \nregion = 'us-east-2'\n#change the Instance ID \ninstances = ['i-**************']\nec2 = boto3.client('ec2', region_name=region)\n\ndef lambda_handler(event, context):\n    # Start instances\n    ec2.stop_instances(InstanceIds=instances)\n    print(f\"Started your instances: {instances}\")\n\n\nEventbridger Schedule\nFor our trading bot, we only want our EC2 to be running during market times as we don’t want to spend money running it 24/7.\nSince our goal is to facilitate when our EC2 is running on a specified schedule we can use Eventbridger Schedule to schedule when our lambda functions run.\nTo do this we need to navigate to the Amazon EventBridger page within the console.\nOnce we’ve reached the page, you can scroll down to the “Get started” section of the page and click “Eventbridger Schedule” and Create rule.\nOnce on this page we can give our schedule a name as well as a discription.\nThen move on to the schedule pattern page, since we are creating a recurring schedule we will click that section.\nFrom here we can dictate the time zone and our cron job expression, letting the scheduler know how often to run this job.\nCron expressions are formatted as so: cron(minutes hours day_of_month month days_of_week year)\nIf the specifics are unknown such as day of month, you can place a ?, if its applicable to all you can place an *.\nSince I want to have it run during stock market hours, I’ve changed the time zone to New York, and set the cron job to run every week day at 9 am:\ncron(0, 9, ?, *, 2-6, *)\nYou can also choose how long you want this schedule to run in the time frame.\nMoving to the next page we will click AWS Lambda Invoke, to dictate that we are wanting the use this schedule on our lambda functions. Then we can choose the function we would like to Invoke, we will leave the json payload empty.\nThen we will click next until we can create our scheduler.\nCongrats you’ve learned the basics of scheduling a lambda function to run your EC2 based off a schedule."
  },
  {
    "objectID": "posts/AlgoTrading/algotradingbasics.html",
    "href": "posts/AlgoTrading/algotradingbasics.html",
    "title": "Algorithmic Trading Basics",
    "section": "",
    "text": "Algorithmic Trading is automated trading at it’s core."
  },
  {
    "objectID": "posts/AlgoTrading/algotradingbasics.html#human-error",
    "href": "posts/AlgoTrading/algotradingbasics.html#human-error",
    "title": "Algorithmic Trading Basics",
    "section": "Human Error",
    "text": "Human Error\nWhen trading a stock or security the goal is to make profit from when you enter the position to where you exit. If you are in a long position you will most likely have some sort of exit indicator that lets you kno when you need to sell, if the stock is still increasing in price that could be difficult.\nThe opposite can be true as well, if your stock is dropping in price and you sell prematurely the stock may rise after causing greif and loss.\n\nFOMO\nFOMO stands for the Fear Of Missing Out. This often comes into play when an individual sees stocks breaking record highs and have been increasing nonstop for the last few time periods, they decide to buy thinking this will never stop. The stock could continue to increase or it could start dropping.\nWhen the stock starts to drop people will hold on longer than they should, hoping that the price will rise again until they final sell, just to see the stock continuing to rise a few days after they sell.\nWe as human beings get into patterns of hope and dispare, having a machine handle trading allows us to take an emotional backseat and trust in the process that we have created."
  },
  {
    "objectID": "posts/AlgoTrading/algotradingbasics.html#allows-for-high-frequency-trading",
    "href": "posts/AlgoTrading/algotradingbasics.html#allows-for-high-frequency-trading",
    "title": "Algorithmic Trading Basics",
    "section": "Allows for High Frequency Trading",
    "text": "Allows for High Frequency Trading\nWith the use of Algorithmic Trading and Automated trading we can use strategies that wouldn’t be feasible without it. Due to the time and speed of the trade taking place. A few strategies that take advantage of this are:\n\nArbitrage: Exploiting price differences between an index and its futures or underlying components\nOrder Book Imbalance: Trading based on real-time buy and sell order imbalances\nCross-Market Arbitrage: Exploting price differences across mulitple markets\n\nMost of these strategies involve some sort of arbitrage, taking advantage of difference in prices in two or more markets."
  },
  {
    "objectID": "posts/AlgoTrading/algotradingbasics.html#large-analysis-minimal-analysis-paralysis",
    "href": "posts/AlgoTrading/algotradingbasics.html#large-analysis-minimal-analysis-paralysis",
    "title": "Algorithmic Trading Basics",
    "section": "Large Analysis ( Minimal Analysis Paralysis)",
    "text": "Large Analysis ( Minimal Analysis Paralysis)\nWhen creating an Algorithmic Trading Bot you have the oppurtunity to allow it to evaluate multiple indicators, and resources before deciding on a strategy or a trade. It gives us more computing power within a smaller amount of time.\n\nAnalysis Paralysis\nAnalysis Paralysis is a concept of analyzing too so much data as to the point where you feel paralyzed not knowing with direction to go or how to react, as there is always a great degree of unknown price movement, expecially within stock prices. Sometimes you need to take action even when unsure of the result, Algo Trading aids in this behavior, allowing you to pull the trigger and take action."
  },
  {
    "objectID": "posts/AlgoTrading/algotradingbasics.html#conclusion",
    "href": "posts/AlgoTrading/algotradingbasics.html#conclusion",
    "title": "Algorithmic Trading Basics",
    "section": "Conclusion",
    "text": "Conclusion\nThere are many benefits of algorithmic trading, I prefer the concept of autonomy, and the prevention or analysis paraylysis. The biggest flaw an algorithmic trading bot has, is the flaws that we bake into it. This can amplify our investments in a positive or a negative direction. It is up to us how we build them."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! I am Tyler an aspiring Data Scientist,\nThis Blog serves as part of my Senior Capstone Project at Brigham Young University of Idaho.\nMy Project entails developing and implementing an Algorithmic Trading Bot. I intially got interested in Data Science through a youth stock trading competition I enrolled in my Sophmore year of Highschool. Now I am returning to the world of financial data with a supercharged skill set.\nThere are mulitple blog posts covering basic concepts, idea exploration, and implementation of strategies."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home Page",
    "section": "",
    "text": "Lambda Functions for Stopping and Starting EC2 Instance\n\n\n\n\n\n\n\nTrading\n\n\nAWS\n\n\nLambda\n\n\nEventBridger\n\n\n\n\n\n\n\n\n\n\n\nMar 29, 2025\n\n\nTyler Binning\n\n\n\n\n\n\n  \n\n\n\n\nCreating an EC2 instance\n\n\n\n\n\n\n\nTrading\n\n\nAWS\n\n\nEC2\n\n\n\n\n\n\n\n\n\n\n\nMar 26, 2025\n\n\nTyler Binning\n\n\n\n\n\n\n  \n\n\n\n\nStatistical Arbitrage Basics\n\n\n\n\n\n\n\nTime Series\n\n\nStats\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2025\n\n\nTyler Binning\n\n\n\n\n\n\n  \n\n\n\n\nAlgorithmic Trading Basics\n\n\n\n\n\n\n\nTrading Bot\n\n\nBasics\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2025\n\n\nTyler Binning\n\n\n\n\n\n\n  \n\n\n\n\nBuilding a Simple Dash App\n\n\n\n\n\n\n\nTrading\n\n\nVisuals\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2025\n\n\nTyler Binning\n\n\n\n\n\n\n  \n\n\n\n\nBasic Strategies\n\n\n\n\n\n\n\nTrading\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2025\n\n\nTyler Binning\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/AWS_Implementation/AWS_applied.html",
    "href": "posts/AWS_Implementation/AWS_applied.html",
    "title": "Creating an EC2 instance",
    "section": "",
    "text": "AWS stands for Amazon Web Services, they provide a number of cloud hosted services with inlcude cloud computing and database storage among other products. Our main focus is going to be on cloud computing and storage for the application with our trading bot. Amazons cloud compute service that we will be using is called EC2 which stands for Elastic Compute Cloud.\n\n\nIn order to run files on the cloud, we need to create our EC2 instance. To do this we: - login to our AWS console. - search “EC2” in the search bar - navigate to the EC2 dashboard - click launch intstance, clicking new\n\n\nOnce you have navigated to launching an instance you can choose your name for the instance - name photo\nFrom there you can choose the Operating System, I’ve choose Amazon Linux\nAfter choosing your OS then you will need to choose your instance type which is dictated by your specific compute needs and the intensity of what you will be running.\nThe more computing power you choose the more expensive your monthly bill will be. That being said there are “Free tier eligible” instance types such as the t2.mirco instance type.\nYou will also want to create a key pair and download it to your local computer as it will be need to connect your laptop or files to your instance in the future. This file will be saved as a .ppk file.\nFrom here you can manage your network settings, for this demo we will leave the default settings.\nYou can then click launch instance and you will have created your first instance! Congrads!"
  },
  {
    "objectID": "posts/AWS_Implementation/AWS_applied.html#ec2",
    "href": "posts/AWS_Implementation/AWS_applied.html#ec2",
    "title": "Creating an EC2 instance",
    "section": "",
    "text": "In order to run files on the cloud, we need to create our EC2 instance. To do this we: - login to our AWS console. - search “EC2” in the search bar - navigate to the EC2 dashboard - click launch intstance, clicking new\n\n\nOnce you have navigated to launching an instance you can choose your name for the instance - name photo\nFrom there you can choose the Operating System, I’ve choose Amazon Linux\nAfter choosing your OS then you will need to choose your instance type which is dictated by your specific compute needs and the intensity of what you will be running.\nThe more computing power you choose the more expensive your monthly bill will be. That being said there are “Free tier eligible” instance types such as the t2.mirco instance type.\nYou will also want to create a key pair and download it to your local computer as it will be need to connect your laptop or files to your instance in the future. This file will be saved as a .ppk file.\nFrom here you can manage your network settings, for this demo we will leave the default settings.\nYou can then click launch instance and you will have created your first instance! Congrads!"
  },
  {
    "objectID": "posts/Building_Dash/Building_Dash.html",
    "href": "posts/Building_Dash/Building_Dash.html",
    "title": "Building a Simple Dash App",
    "section": "",
    "text": "Basic Components\n\n\nFormating\n\n\nSecurity\n\n\nCallbacks\n\n\nStyling"
  },
  {
    "objectID": "posts/stat_arbitrage/stat_arb.html",
    "href": "posts/stat_arbitrage/stat_arb.html",
    "title": "Statistical Arbitrage Basics",
    "section": "",
    "text": "The purpose of this document is to be a collective on the basic ideas and strategies for StatArb. This will be set up for easy reference.\n\n\nInvolves exploiting pricing discrepancies or deviations from expected statistical relationships between related securities or financial instruments.\nThe basic ideology is that certain relationships between securities tend to revert to their mean or exibit predictable patterns over time.\n\n\n\nPair Selection: selecting groups of related securities believed to demonstrated statistical relationships. Relationship can be based off: - historical price patterns - correlation analysis - fundamental characteristics\nModel Dev: model developed to estimate the expected behavior of the pair of securities. Based off of: - statistical techniques - time sries analysis - machine learning models - quantitative methods\nDeviation Detection: model mnitors the prices or other relevant indicators, when a deviation from the expected relaionship is detected a trading signal is created. Deviation can be measured through: - z-scores - moving averages - other indicators\nTrade Execution: Involves buying one security and selling another security. Aiming to capture price discreptancies\nRisk Management: Need to employ risk controls: - stop-loss orders - position sizing rules - portfolio diversification\n\n\n\nWhen selecting pairs we want to identify assests with high correlation. A common example is Coca-Cola and PepsiCo as they have similar products and business models. There is a certain fundamental connection and a technical connection.\nIf the price relationship of the securities deviates from their long term average; “managers expecting the deviation to be temporary would go long on the underperforming stock (e.g., Coca-Cola) and simultaneously short the outperforming stock (e.g., PepsiCo).” (Analyst Prep)\nSo we are looking at the relationship between two stocks and when the value of one moves out of a certain range around their average, then you expect the value of one to drop and the other to rise, to move back to the mean.\nSo you short the top, and buy go long on the bottom, expecting them to meet in the middle.\nHow can we use ARIMA with this?? Can we use the ARIMA to predict the average of two different securities, to determine where the price deviations may meet up in the future?\n\n\nConintegration is a measure of the relationship between several time series in the longterm. - Introducted by Robert Engle and Clive Granfer in 1987\n“Cointegration tests identify scenarios where two or more non-stationary time series are integrated together in a way that they cannot deviate from equilibrium in the long term. The tests are used to identify the degree of sensitivity of two variables to the same average price over a specified period of time.”(CFI)\nBy defination the cointegration test determines whether the securities can’t deviate from each other in the long term. Which is great for our statisical arbitrage models, as we are just wanting to capture temporary discreptancies.\nTo perform this test we leave the time series data as non-stationary.\nCould we use a ML model to help determine whether this is a temporary discreptancy or a long term change?\n\n\n\n1. Engle-Granger Two-Step Method Limitations: - if there are more than two variables, the method may show more than two cointegrated relationships - it’s a single equation model\n2.Johansen Test Used to test cointegrating relationships between several nonpstationary time series data. Allows for more than one cointegrating relationship. small sample size would provide unreliable results\nComes in two forms:\n-Trace Tests Tests the number of linear combinations in time series data\n\\[\nH_0: K = K_0\n\\] \\[\nH_a: K &gt; K_0\n\\]\n-Maximum Eigenvalue Test \\[\nH_0: K = K_0\n\\] \\[\nH_a: K = K_0 + 1\n\\]\n\n\n\n\n\n\n\nQ’s: Can we leverage options?"
  },
  {
    "objectID": "posts/stat_arbitrage/stat_arb.html#what-is-statistical-arbitrage",
    "href": "posts/stat_arbitrage/stat_arb.html#what-is-statistical-arbitrage",
    "title": "Statistical Arbitrage Basics",
    "section": "",
    "text": "Involves exploiting pricing discrepancies or deviations from expected statistical relationships between related securities or financial instruments.\nThe basic ideology is that certain relationships between securities tend to revert to their mean or exibit predictable patterns over time."
  },
  {
    "objectID": "posts/stat_arbitrage/stat_arb.html#how",
    "href": "posts/stat_arbitrage/stat_arb.html#how",
    "title": "Statistical Arbitrage Basics",
    "section": "",
    "text": "Pair Selection: selecting groups of related securities believed to demonstrated statistical relationships. Relationship can be based off: - historical price patterns - correlation analysis - fundamental characteristics\nModel Dev: model developed to estimate the expected behavior of the pair of securities. Based off of: - statistical techniques - time sries analysis - machine learning models - quantitative methods\nDeviation Detection: model mnitors the prices or other relevant indicators, when a deviation from the expected relaionship is detected a trading signal is created. Deviation can be measured through: - z-scores - moving averages - other indicators\nTrade Execution: Involves buying one security and selling another security. Aiming to capture price discreptancies\nRisk Management: Need to employ risk controls: - stop-loss orders - position sizing rules - portfolio diversification"
  },
  {
    "objectID": "posts/stat_arbitrage/stat_arb.html#methods-for-pair-selection",
    "href": "posts/stat_arbitrage/stat_arb.html#methods-for-pair-selection",
    "title": "Statistical Arbitrage Basics",
    "section": "",
    "text": "When selecting pairs we want to identify assests with high correlation. A common example is Coca-Cola and PepsiCo as they have similar products and business models. There is a certain fundamental connection and a technical connection.\nIf the price relationship of the securities deviates from their long term average; “managers expecting the deviation to be temporary would go long on the underperforming stock (e.g., Coca-Cola) and simultaneously short the outperforming stock (e.g., PepsiCo).” (Analyst Prep)\nSo we are looking at the relationship between two stocks and when the value of one moves out of a certain range around their average, then you expect the value of one to drop and the other to rise, to move back to the mean.\nSo you short the top, and buy go long on the bottom, expecting them to meet in the middle.\nHow can we use ARIMA with this?? Can we use the ARIMA to predict the average of two different securities, to determine where the price deviations may meet up in the future?\n\n\nConintegration is a measure of the relationship between several time series in the longterm. - Introducted by Robert Engle and Clive Granfer in 1987\n“Cointegration tests identify scenarios where two or more non-stationary time series are integrated together in a way that they cannot deviate from equilibrium in the long term. The tests are used to identify the degree of sensitivity of two variables to the same average price over a specified period of time.”(CFI)\nBy defination the cointegration test determines whether the securities can’t deviate from each other in the long term. Which is great for our statisical arbitrage models, as we are just wanting to capture temporary discreptancies.\nTo perform this test we leave the time series data as non-stationary.\nCould we use a ML model to help determine whether this is a temporary discreptancy or a long term change?\n\n\n\n1. Engle-Granger Two-Step Method Limitations: - if there are more than two variables, the method may show more than two cointegrated relationships - it’s a single equation model\n2.Johansen Test Used to test cointegrating relationships between several nonpstationary time series data. Allows for more than one cointegrating relationship. small sample size would provide unreliable results\nComes in two forms:\n-Trace Tests Tests the number of linear combinations in time series data\n\\[\nH_0: K = K_0\n\\] \\[\nH_a: K &gt; K_0\n\\]\n-Maximum Eigenvalue Test \\[\nH_0: K = K_0\n\\] \\[\nH_a: K = K_0 + 1\n\\]"
  },
  {
    "objectID": "posts/stat_arbitrage/stat_arb.html#trade-execution",
    "href": "posts/stat_arbitrage/stat_arb.html#trade-execution",
    "title": "Statistical Arbitrage Basics",
    "section": "",
    "text": "Q’s: Can we leverage options?"
  }
]